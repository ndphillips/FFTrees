<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="FFTrees">
<title>Accuracy statistics in FFTrees • FFTrees</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Accuracy statistics in FFTrees">
<meta property="og:description" content="FFTrees">
<meta property="og:image" content="https://ndphillips.github.io/FFTrees/logo.png">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">FFTrees</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">2.0.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/FFTrees_accuracy_statistics.html">Accuracy statistics in FFTrees</a>
    <a class="dropdown-item" href="../articles/FFTrees_examples.html">Examples of FFTrees</a>
    <a class="dropdown-item" href="../articles/FFTrees_function.html">Creating FFTs with FFTrees()</a>
    <a class="dropdown-item" href="../articles/FFTrees_heart.html">Tutorial: Creating FFTs for heart disease</a>
    <a class="dropdown-item" href="../articles/FFTrees_mytree.html">Manually specifying FFTs</a>
    <a class="dropdown-item" href="../articles/FFTrees_plot.html">Visualising FFTs</a>
    <a class="dropdown-item" href="../articles/guide.html">Overview: Creating FFTs with FFTrees</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/ndphillips/FFTrees/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Accuracy statistics in FFTrees</h1>
                        <h4 data-toc-skip class="author">Nathaniel
Phillips and Hansjörg Neth</h4>
            
            <h4 data-toc-skip class="date">2024-05-22</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/ndphillips/FFTrees/blob/HEAD/vignettes/FFTrees_accuracy_statistics.Rmd" class="external-link"><code>vignettes/FFTrees_accuracy_statistics.Rmd</code></a></small>
      <div class="d-none name"><code>FFTrees_accuracy_statistics.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="accuracy-statistics-in-fftrees">Accuracy Statistics in <strong>FFTrees</strong><a class="anchor" aria-label="anchor" href="#accuracy-statistics-in-fftrees"></a>
</h2>
<p>In this vignette, we cover how accuracy statistics are calculated for
FFTs and the <strong>FFTrees</strong> package <span class="citation">(as
described in Phillips et al., 2017)</span>. Most of these measures are
not specific to FFTs and can be used for any classification
algorithm.</p>
<p>First, let’s examine the accuracy statistics from an FFT predicting
heart disease:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create an FFTrees object predicting heart disease: </span></span>
<span><span class="va">heart.fft</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/FFTrees.html">FFTrees</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">diagnosis</span> <span class="op">~</span><span class="va">.</span>,</span>
<span>                     data <span class="op">=</span> <span class="va">heartdisease</span><span class="op">)</span></span></code></pre></div>
<p>Running this <code><a href="../reference/FFTrees.html">FFTrees()</a></code> function call yields a new
<code>FFTrees</code> object <code>heart.fft</code>. Both printing or
plotting this object for a particular dataset and tree yields
corresponding accuracy and frugality statistics. For now, we simply plot
the best training tree:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">heart.fft</span>, tree <span class="op">=</span> <span class="st">"best.train"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="FFTrees_accuracy_statistics_files/figure-html/fft-plot-1-1.png" alt="**Figure 1**: Example FFT for the `heartdisease` data." width="580px"><p class="caption">
<strong>Figure 1</strong>: Example FFT for the <code>heartdisease</code>
data.
</p>
</div>
<p>We notice a 2x2 table in the bottom-left corner of the plot: This is
a <em>2 x 2 matrix</em> or <em>confusion table</em> (see <a href="https://en.wikipedia.org/wiki/Confusion_matrix" class="external-link">Wikipedia</a> or
<a href="https://doi.org/10.3389/fpsyg.2020.567817" class="external-link">Neth et al.,
2021</a> for details). A wide range of accuracy measures can be derived
from this seemingly simple matrix. Here is a generic version of a
confusion table:</p>
<div class="figure" style="text-align: center">
<img src="confusiontable.jpg" alt="**Figure 2**: A 2x2 matrix illustrating the frequency counts of 4 possible outcomes." width="50%"><p class="caption">
<strong>Figure 2</strong>: A 2x2 matrix illustrating the frequency
counts of 4 possible outcomes.
</p>
</div>
<p>A 2 x 2 matrix cross-tabulates the decisions of the algorithm (rows)
with actual criterion values (columns) and contains counts of
observations for all four resulting cells. Counts in cells a and d refer
to correct decisions due to a match between predicted and criterion
values, whereas counts in cells b and c refer to errors due to the
mismatch between predicted and criterion values. Both correct decisions
and errors come in two types:</p>
<ul>
<li><p>Correct decisions in cell <em>hi</em> represent <em>hits</em>,
positive criterion values correctly predicted to be positive, and
cell <em>cr</em> represents <em>correct rejections</em>, negative
criterion values correctly predicted to be negative.</p></li>
<li><p>As for errors, cell <em>fa</em> represents <em>false alarms</em>,
negative criterion values erroneously predicted to be positive, and
cell <em>mi</em> represents <em>misses</em>, positive criterion values
erroneously predicted to be negative.</p></li>
</ul>
<p>Given this structure, an accurate decision algorithm aims to maximize
the frequencies in cells <em>hi</em> and <em>cr</em> while minimizing
those in cells <em>fa</em> and <em>mi</em>.</p>
<table class="table">
<colgroup>
<col width="12%">
<col width="50%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th align="left">Output</th>
<th align="left">Description</th>
<th align="left">Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><code>hi</code></td>
<td align="left">Number of hits</td>
<td align="left"><span class="math inline">\(N(\text{Decision} = 1 \land
\text{Truth} = 1)\)</span></td>
</tr>
<tr class="even">
<td align="left"><code>mi</code></td>
<td align="left">Number of misses</td>
<td align="left"><span class="math inline">\(N(\text{Decision} = 0 \land
\text{Truth} = 1)\)</span></td>
</tr>
<tr class="odd">
<td align="left"><code>fa</code></td>
<td align="left">Number of false-alarms</td>
<td align="left"><span class="math inline">\(N(\text{Decision} = 1 \land
\text{Truth} = 0)\)</span></td>
</tr>
<tr class="even">
<td align="left"><code>cr</code></td>
<td align="left">Number of correct rejections</td>
<td align="left"><span class="math inline">\(N(\text{Decision} = 0 \land
\text{Truth} = 0)\)</span></td>
</tr>
<tr class="odd">
<td align="left"><code>N</code></td>
<td align="left">Total number of cases</td>
<td align="left"><span class="math inline">\(\text{N} = \text{hi} +
\text{mi} + \text{fa} + \text{cr}\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Table 1</strong>: Definitions of the frequency counts in a
2x2 confusion table. The notation <span class="math inline">\(N()\)</span> means number of cases (or frequency
counts).</p>
<div class="section level3">
<h3 id="conditional-accuracy-statistics">Conditional accuracy statistics<a class="anchor" aria-label="anchor" href="#conditional-accuracy-statistics"></a>
</h3>
<p>The first set of accuracy statistics are based on subsets of the
data. These subsets result from focusing on particular cases of interest
and computing conditional probabilities based on them. Given the 2x2
structure of the confusion table, measures can be conditional on either
algorithm decisions (positive predictive vs. negative predictive values)
or criterion values (sensitivity vs. specificity). In other words, these
measures are conditional probabilities that are based on either the rows
or columns of the confusion table:</p>
<table class="table">
<colgroup>
<col width="11%">
<col width="50%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th align="left">Output</th>
<th align="left">Description</th>
<th align="left">Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><code>sens</code></td>
<td align="left">Sensitivity</td>
<td align="left"><span class="math inline">\(p(\text{Decision} = 1 \
\vert\ \text{Truth} = 1) = \text{hi} / (\text{hi} +
\text{mi})\)</span></td>
</tr>
<tr class="even">
<td align="left"><code>spec</code></td>
<td align="left">Specificity</td>
<td align="left"><span class="math inline">\(p(\text{Decision} = 0 \
\vert\ \text{Truth} = 0) = \text{cr} / (\text{cr} +
\text{fa})\)</span></td>
</tr>
<tr class="odd">
<td align="left"><code>far</code></td>
<td align="left">False alarm rate</td>
<td align="left">
<span class="math inline">\(1 -
\text{Specificity}\)</span> (<code>spec</code>)</td>
</tr>
<tr class="even">
<td align="left"><code>ppv</code></td>
<td align="left">Positive predictive value</td>
<td align="left"><span class="math inline">\(p(\text{Truth} = 1 \ \vert\
\text{Decision} = 1) = \text{hi} / (\text{hi} + \text{fa})\)</span></td>
</tr>
<tr class="odd">
<td align="left"><code>npv</code></td>
<td align="left">Negative predictive value</td>
<td align="left"><span class="math inline">\(p(\text{Truth} = 0 \ \vert\
\text{Decision} = 0) = \text{cr} / (\text{cr} + \text{mi})\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Table 2</strong>: Conditional accuracy statistics based on
either the rows or columns of a 2x2 confusion table.</p>
<p>The <em>sensitivity</em> (aka. <em>hit-rate</em>) is defined as <span class="math inline">\(sens = hi/(hi + mi)\)</span> and represents the
percentage of cases with positive criterion values that were correctly
predicted by the algorithm. Similarly, <em>specificity</em> (aka.
<em>correct rejection rate</em>, or the complement of the <em>false
alarm rate</em>) is defined as <span class="math inline">\(spec = cr/(fa
+ cr)\)</span> and represents the percentage of cases with negative
criterion values correctly predicted by the algorithm.</p>
<p>The <em>positive-predictive value</em> <span class="math inline">\(ppv\)</span> and <em>negative predictive
value</em> <span class="math inline">\(npv\)</span> are the flip-sides
of <span class="math inline">\(sens\)</span> and <span class="math inline">\(spec\)</span>, as they are conditional accuracies
based on decision outcomes (rather than on true criterion values).</p>
</div>
<div class="section level3">
<h3 id="aggregate-accuracy-statistics">Aggregate accuracy statistics<a class="anchor" aria-label="anchor" href="#aggregate-accuracy-statistics"></a>
</h3>
<p>Additional accuracy statistics are based on all four cells in the
confusion table:</p>
<table class="table">
<colgroup>
<col width="11%">
<col width="50%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th align="left">Output</th>
<th align="left">Description</th>
<th align="left">Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><code>acc</code></td>
<td align="left">Accuracy</td>
<td align="left"><span class="math inline">\((\text{hi} + \text{cr}) /
(\text{hi} + \text{mi} + \text{fa} + \text{cr})\)</span></td>
</tr>
<tr class="even">
<td align="left"><code>bacc</code></td>
<td align="left">Balanced accuracy</td>
<td align="left"><span class="math inline">\(\text{sens} \times .5 +
\text{spec} \times .5\)</span></td>
</tr>
<tr class="odd">
<td align="left"><code>wacc</code></td>
<td align="left">Weighted accuracy</td>
<td align="left"><span class="math inline">\(\text{sens} \times w +
\text{spec} \times (1 - w)\)</span></td>
</tr>
<tr class="even">
<td align="left"><code>bpv</code></td>
<td align="left">Balanced predictive value</td>
<td align="left"><span class="math inline">\(\text{ppv} \times .5 +
\text{npv} \times .5\)</span></td>
</tr>
<tr class="odd">
<td align="left"><code>dprime</code></td>
<td align="left">D-prime</td>
<td align="left"><span class="math inline">\(z_{\text{sens}} -
z_{\text{far}}\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Table 3</strong>: Aggregate accuracy statistics based on all
four cells of a 2x2 confusion table.</p>
<p>Overall <em>accuracy</em> (<code>acc</code>) is defined as the
overall percentage of correct decisions ignoring the difference between
hits and correct rejections. The more specific measures <span class="math inline">\(bacc\)</span> and <span class="math inline">\(wacc\)</span> are averages of sensitivity and
specificity, while <span class="math inline">\(bpv\)</span> is an
average of predictive values. The <span class="math inline">\(dprime\)</span> measure is the difference in
standardized (<span class="math inline">\(z\)</span>-score)
transformed <span class="math inline">\(sens\)</span> and <span class="math inline">\(far\)</span> <span class="citation">(see Luan et
al., 2011 for the relation between FFTs and signal detection theory,
SDT)</span>.</p>
</div>
<div class="section level3">
<h3 id="speed-and-frugality-statistics">Speed and frugality statistics<a class="anchor" aria-label="anchor" href="#speed-and-frugality-statistics"></a>
</h3>
<p>The next two statistics measure the speed and frugality of a
fast-and-frugal tree (FFT). Unlike the accuracy statistics above, they
are <em>not</em> based on the confusion table. Rather, they depend on
how much information FFTs use to make their predictions or
decisions.</p>
<table class="table">
<colgroup>
<col width="9%">
<col width="58%">
<col width="31%">
</colgroup>
<thead><tr class="header">
<th align="left">Output</th>
<th align="left">Description</th>
<th align="left">Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><code>mcu</code></td>
<td align="left">Mean cues used: Average number of cue values used in
making classifications, averaged across all cases</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"><code>pci</code></td>
<td align="left">Percentage of cues ignored: Percentage of cues ignored
when classifying cases</td>
<td align="left"><span class="math inline">\(N(\text{cues in data}) -
\text{mcu}\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Table 4</strong>: Measures to quantify the speed and
frugality of FFTs.</p>
<p>To see exactly where these statistics come from, let’s look at the
results for <code>heart.fft</code> (Tree #1):</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">heart.fft</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; <span style="color: #005FAF;">FFTrees </span></span></span>
<span><span class="co">#&gt; - Trees: 7 fast-and-frugal trees predicting <span style="text-decoration: underline;">diagnosis</span></span></span>
<span><span class="co">#&gt; - Cost of outcomes:  hi = 0,  fa = 1,  mi = 1,  cr = 0</span></span>
<span><span class="co">#&gt; - Cost of cues: </span></span>
<span><span class="co">#&gt;      age      sex       cp trestbps     chol      fbs  restecg  thalach </span></span>
<span><span class="co">#&gt;        1        1        1        1        1        1        1        1 </span></span>
<span><span class="co">#&gt;    exang  oldpeak    slope       ca     thal </span></span>
<span><span class="co">#&gt;        1        1        1        1        1 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #005FAF;">FFT #1: Definition</span></span></span>
<span><span class="co">#&gt; [1] If thal = {rd,fd}, decide True.</span></span>
<span><span class="co">#&gt; [2] If cp != {a}, decide False.</span></span>
<span><span class="co">#&gt; [3] If ca &gt; 0, decide True, otherwise, decide False.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #005FAF;">FFT #1: </span><span style="color: #005FAF; text-decoration: underline;">Training</span><span style="color: #005FAF;"> Accuracy</span></span></span>
<span><span class="co"><span style="color: #005FAF;">#&gt; </span>Training data: N = 303, Pos (+) = 139 (46%) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; |          | True + | True - | Totals:</span></span>
<span><span class="co">#&gt; |----------|--------|--------|</span></span>
<span><span class="co">#&gt; | Decide + | <span style="color: #767676;">hi</span> <span style="color: #00AF00;">118</span> | <span style="color: #767676;">fa</span>  <span style="color: #D70000;">37</span> |     155</span></span>
<span><span class="co">#&gt; | Decide - | <span style="color: #767676;">mi</span>  <span style="color: #D70000;">21</span> | <span style="color: #767676;">cr</span> <span style="color: #00AF00;">127</span> |     148</span></span>
<span><span class="co">#&gt; |----------|--------|--------|</span></span>
<span><span class="co">#&gt;   Totals:       139      164   N = <span style="text-decoration: underline;">303</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; acc  = 80.9%   ppv  = 76.1%   npv  = 85.8%</span></span>
<span><span class="co">#&gt; bacc = 81.2%   sens = 84.9%   spec = 77.4%</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #005FAF;">FFT #1: </span><span style="color: #005FAF; text-decoration: underline;">Training</span><span style="color: #005FAF;"> Speed, Frugality, and Cost</span></span></span>
<span><span class="co"><span style="color: #005FAF;">#&gt; </span>mcu = 1.73,  pci = 0.87</span></span>
<span><span class="co">#&gt; cost_dec = 0.191,  cost_cue = 1.733,  cost = 1.924</span></span></code></pre>
<p>According to this output, Tree #1 has <code>mcu = 1.73</code> and
<code>pci = 0.87</code>. We can easily calculate these measures directly
from the <code>x$levelout</code> output of an <code>FFTrees</code>
object. This object contains the tree level (i.e., node) at which each
case was classified:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># A vector of levels/nodes at which each case was classified:</span></span>
<span><span class="va">heart.fft</span><span class="op">$</span><span class="va">trees</span><span class="op">$</span><span class="va">decisions</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">tree_1</span><span class="op">$</span><span class="va">levelout</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt;   [1] 1 3 1 2 2 2 3 3 1 1 1 2 1 1 1 2 1 3 2 2 2 2 2 1 1 2 2 2 3 1 2 1 2 1 2 3 1</span></span>
<span><span class="co">#&gt;  [38] 1 1 2 1 1 2 2 3 1 2 1 2 2 2 1 3 2 1 1 1 1 2 2 1 2 1 2 1 1 2 1 1 2 2 1 1 1</span></span>
<span><span class="co">#&gt;  [75] 3 2 1 2 2 1 3 3 2 1 2 2 2 2 3 2 3 1 1 2 2 1 1 1 2 3 3 2 3 2 1 1 1 1 1 1 1</span></span>
<span><span class="co">#&gt; [112] 3 1 1 1 1 2 3 1 1 1 1 2 1 2 2 1 1 2 3 1 1 2 3 2 2 1 1 1 2 2 1 2 1 1 2 1 2</span></span>
<span><span class="co">#&gt; [149] 2 2 1 3 1 1 3 3 1 1 1 1 1 3 2 3 2 1 2 2 1 2 1 1 3 3 1 1 1 1 2 2 1 1 2 1 3</span></span>
<span><span class="co">#&gt; [186] 2 1 1 1 1 2 1 1 3 2 3 2 3 2 2 3 3 1 1 1 1 1 1 2 3 2 1 2 1 3 1 2 3 3 3 2 2</span></span>
<span><span class="co">#&gt; [223] 2 1 3 2 3 2 3 3 2 3 2 2 2 3 1 1 2 2 2 2 3 2 2 3 1 3 1 2 1 1 1 2 3 2 3 2 2</span></span>
<span><span class="co">#&gt; [260] 1 2 2 2 2 3 1 3 1 1 2 1 1 1 3 2 1 2 2 2 3 1 2 1 2 1 1 1 1 1 2 1 2 1 1 3 2</span></span>
<span><span class="co">#&gt; [297] 1 1 1 1 1 2 2</span></span></code></pre>
<p>Now, to calculate <code>mcu</code> (the <em>mean number of cues
used</em>), we simply take the mean of this vector:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Calculate the mean number or cues used (mcu): </span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">heart.fft</span><span class="op">$</span><span class="va">trees</span><span class="op">$</span><span class="va">decisions</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">tree_1</span><span class="op">$</span><span class="va">levelout</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; [1] 1.732673</span></span></code></pre>
<p>Now that we know where <code>mcu</code> comes from, computing
<code>pci</code> (i.e., the <em>percentage of cues ignored</em>) is just
as simple — it’s just the total number of cues in the dataset
minus <code>mcu</code>, divided by the total number of cues in the
data:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Calculate pci (percentage of cues ignored) as </span></span>
<span><span class="co"># (n.cues - mcu) / n.cues):</span></span>
<span><span class="va">n.cues</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">heartdisease</span><span class="op">)</span> </span>
<span><span class="op">(</span><span class="va">n.cues</span> <span class="op">-</span> <span class="va">heart.fft</span><span class="op">$</span><span class="va">trees</span><span class="op">$</span><span class="va">stats</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">mcu</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="op">/</span> <span class="va">n.cues</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; [1] 0.8762376</span></span></code></pre>
<!-- Reference for further measures: -->
</div>
<div class="section level3">
<h3 id="additional-measures">Additional measures<a class="anchor" aria-label="anchor" href="#additional-measures"></a>
</h3>
<p>There is a wide range of additional measures that can be used to
quantify classification performance. Most of these can easily be
computed from the numerical information provided in an
<code>FFTrees</code> object. For alternative measures based on the
frequency counts of a 2x2 matrix, see <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2020.567817/full#h5" class="external-link">Table
3</a> of <span class="citation">Neth et al. (2021)</span>.</p>
<!-- - Neth, H., Gradwohl, N., Streeb, D., Keim, D.A., & Gaissmaier, W. (2021).  -->
<!-- Perspectives on the 2×2 matrix: Solving semantically distinct problems based on a shared structure of binary contingencies. _Frontiers in Psychology_, _11_, 567817. doi: [10.3389/fpsyg.2020.567817](https://doi.org/10.3389/fpsyg.2020.567817) -->
</div>
</div>
<div class="section level2">
<h2 id="vignettes">Vignettes<a class="anchor" aria-label="anchor" href="#vignettes"></a>
</h2>
<!-- Table of all vignettes: -->
<p>Here is a complete list of the vignettes available in the
<strong>FFTrees</strong> package:</p>
<table class="table">
<colgroup>
<col width="3%">
<col width="36%">
<col width="59%">
</colgroup>
<thead><tr class="header">
<th align="right"></th>
<th align="left">Vignette</th>
<th align="left">Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right"></td>
<td align="left"><a href="guide.html">Main guide: FFTrees
overview</a></td>
<td align="left">An overview of the <strong>FFTrees</strong>
package</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left"><a href="FFTrees_heart.html">Tutorial: FFTs for heart
disease</a></td>
<td align="left">An example of using <code><a href="../reference/FFTrees.html">FFTrees()</a></code> to model
heart disease diagnosis</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="left"><a href="FFTrees_accuracy_statistics.html">Accuracy
statistics</a></td>
<td align="left">Definitions of accuracy statistics used throughout the
package</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="left"><a href="FFTrees_function.html">Creating FFTs with
FFTrees()</a></td>
<td align="left">Details on the main <code><a href="../reference/FFTrees.html">FFTrees()</a></code>
function</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="left"><a href="FFTrees_mytree.html">Specifying FFTs
directly</a></td>
<td align="left">How to directly create FFTs without using the built-in
algorithms</td>
</tr>
<tr class="even">
<td align="right">5</td>
<td align="left"><a href="FFTrees_plot.html">Visualizing FFTs</a></td>
<td align="left">Plotting <code>FFTrees</code> objects, from full trees
to icon arrays</td>
</tr>
<tr class="odd">
<td align="right">6</td>
<td align="left"><a href="FFTrees_examples.html">Examples of
FFTs</a></td>
<td align="left">Examples of FFTs from different datasets contained in
the package</td>
</tr>
</tbody>
</table>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<!-- eof. -->
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0" line-spacing="2">
<div id="ref-luan2011signal" class="csl-entry">
Luan, S., Schooler, L. J., &amp; Gigerenzer, G. (2011). A
signal-detection analysis of fast-and-frugal trees. <em>Psychological
Review</em>, <em>118</em>(2), 316–338. <a href="https://doi.org/10.1037/a0022684" class="external-link">https://doi.org/10.1037/a0022684</a>
</div>
<div id="ref-neth2021matrix" class="csl-entry">
Neth, H., Gradwohl, N., Streeb, D., Keim, D. A., &amp; Gaissmaier, W.
(2021). <span class="nocase">Perspectives on the 2x2 Matrix: Solving
semantically distinct problems based on a shared structure of binary
contingencies</span>. <em>Frontiers in Psychology</em>, <em>11</em>,
567817. <a href="https://doi.org/10.3389/fpsyg.2020.567817" class="external-link">https://doi.org/10.3389/fpsyg.2020.567817</a>
</div>
<div id="ref-phillips2017FFTrees" class="csl-entry">
Phillips, N. D., Neth, H., Woike, J. K., &amp; Gaissmaier, W. (2017).
<span class="nocase">FFTrees: A toolbox to create, visualize, and
evaluate fast-and-frugal decision trees</span>. <em>Judgment and
Decision Making</em>, <em>12</em>(4), 344–368. <a href="https://doi.org/10.1017/S1930297500006239" class="external-link">https://doi.org/10.1017/S1930297500006239</a>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Nathaniel Phillips, Hansjoerg Neth, Jan Woike, Wolfgang Gaissmaier.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
