<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Accuracy statistics in FFTrees • FFTrees</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Accuracy statistics in FFTrees">
<meta name="robots" content="noindex">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">FFTrees</a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">2.0.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/FFTrees_accuracy_statistics.html">Accuracy statistics in FFTrees</a></li>
    <li><a class="dropdown-item" href="../articles/FFTrees_examples.html">Examples of FFTrees</a></li>
    <li><a class="dropdown-item" href="../articles/FFTrees_function.html">Creating FFTs with FFTrees()</a></li>
    <li><a class="dropdown-item" href="../articles/FFTrees_heart.html">Tutorial: Creating FFTs for heart disease</a></li>
    <li><a class="dropdown-item" href="../articles/FFTrees_mytree.html">Manually specifying FFTs</a></li>
    <li><a class="dropdown-item" href="../articles/FFTrees_plot.html">Visualising FFTs</a></li>
    <li><a class="dropdown-item" href="../articles/guide.html">Overview: Creating FFTs with FFTrees</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/ndphillips/FFTrees/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Accuracy statistics in FFTrees</h1>
                        <h4 data-toc-skip class="author">Nathaniel
Phillips and Hansjörg Neth</h4>
            
            <h4 data-toc-skip class="date">2024-07-20</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/ndphillips/FFTrees/blob/master/vignettes/FFTrees_accuracy_statistics.Rmd" class="external-link"><code>vignettes/FFTrees_accuracy_statistics.Rmd</code></a></small>
      <div class="d-none name"><code>FFTrees_accuracy_statistics.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="accuracy-statistics-in-fftrees">Accuracy Statistics in <strong>FFTrees</strong><a class="anchor" aria-label="anchor" href="#accuracy-statistics-in-fftrees"></a>
</h2>
<p>In this vignette, we cover how accuracy statistics are calculated for
FFTs and the <strong>FFTrees</strong> package <span class="citation">(as
described in Phillips et al., 2017)</span>. Most of these measures are
not specific to FFTs and can be used for any classification
algorithm.</p>
<p>First, let’s examine the accuracy statistics from an FFT predicting
heart disease:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create an FFTrees object predicting heart disease: </span></span>
<span><span class="va">heart.fft</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/FFTrees.html">FFTrees</a></span><span class="op">(</span>formula <span class="op">=</span> <span class="va">diagnosis</span> <span class="op">~</span><span class="va">.</span>,</span>
<span>                     data <span class="op">=</span> <span class="va">heartdisease</span><span class="op">)</span></span></code></pre></div>
<p>Running this <code><a href="../reference/FFTrees.html">FFTrees()</a></code> function call yields a new
<code>FFTrees</code> object <code>heart.fft</code>. Both printing or
plotting this object for a particular dataset and tree yields
corresponding accuracy and frugality statistics. For now, we simply plot
the best training tree:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">heart.fft</span>, tree <span class="op">=</span> <span class="st">"best.train"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="FFTrees_accuracy_statistics_files/figure-html/fft-plot-1-1.png" alt="**Figure 1**: Example FFT for the `heartdisease` data." width="580px"><p class="caption">
<strong>Figure 1</strong>: Example FFT for the <code>heartdisease</code>
data.
</p>
</div>
<p>We notice a 2x2 table in the bottom-left corner of the plot: This is
a <em>2 x 2 matrix</em> or <em>confusion table</em> (see <a href="https://en.wikipedia.org/wiki/Confusion_matrix" class="external-link">Wikipedia</a> or
<a href="https://doi.org/10.3389/fpsyg.2020.567817" class="external-link">Neth et al.,
2021</a> for details). A wide range of accuracy measures can be derived
from this seemingly simple matrix. Here is a generic version of a
confusion table:</p>
<div class="figure" style="text-align: center">
<img src="confusiontable.jpg" alt="**Figure 2**: A 2x2 matrix illustrating the frequency counts of 4 possible outcomes." width="50%"><p class="caption">
<strong>Figure 2</strong>: A 2x2 matrix illustrating the frequency
counts of 4 possible outcomes.
</p>
</div>
<p>A 2 x 2 matrix cross-tabulates the decisions of the algorithm (rows)
with actual criterion values (columns) and contains counts of
observations for all four resulting cells. Counts in cells a and d refer
to correct decisions due to a match between predicted and criterion
values, whereas counts in cells b and c refer to errors due to the
mismatch between predicted and criterion values. Both correct decisions
and errors come in two types:</p>
<ul>
<li><p>Correct decisions in cell <em>hi</em> represent <em>hits</em>,
positive criterion values correctly predicted to be positive, and
cell <em>cr</em> represents <em>correct rejections</em>, negative
criterion values correctly predicted to be negative.</p></li>
<li><p>As for errors, cell <em>fa</em> represents <em>false alarms</em>,
negative criterion values erroneously predicted to be positive, and
cell <em>mi</em> represents <em>misses</em>, positive criterion values
erroneously predicted to be negative.</p></li>
</ul>
<p>Given this structure, an accurate decision algorithm aims to maximize
the frequencies in cells <em>hi</em> and <em>cr</em> while minimizing
those in cells <em>fa</em> and <em>mi</em>.</p>
<table class="table">
<colgroup>
<col width="12%">
<col width="50%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th align="left">Output</th>
<th align="left">Description</th>
<th align="left">Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><code>hi</code></td>
<td align="left">Number of hits</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">Decision</mtext><mo>=</mo><mn>1</mn><mo>∧</mo><mtext mathvariant="normal">Truth</mtext><mo>=</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">N(\text{Decision} = 1 \land \text{Truth} = 1)</annotation></semantics></math></td>
</tr>
<tr class="even">
<td align="left"><code>mi</code></td>
<td align="left">Number of misses</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">Decision</mtext><mo>=</mo><mn>0</mn><mo>∧</mo><mtext mathvariant="normal">Truth</mtext><mo>=</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">N(\text{Decision} = 0 \land \text{Truth} = 1)</annotation></semantics></math></td>
</tr>
<tr class="odd">
<td align="left"><code>fa</code></td>
<td align="left">Number of false-alarms</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">Decision</mtext><mo>=</mo><mn>1</mn><mo>∧</mo><mtext mathvariant="normal">Truth</mtext><mo>=</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">N(\text{Decision} = 1 \land \text{Truth} = 0)</annotation></semantics></math></td>
</tr>
<tr class="even">
<td align="left"><code>cr</code></td>
<td align="left">Number of correct rejections</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">Decision</mtext><mo>=</mo><mn>0</mn><mo>∧</mo><mtext mathvariant="normal">Truth</mtext><mo>=</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">N(\text{Decision} = 0 \land \text{Truth} = 0)</annotation></semantics></math></td>
</tr>
<tr class="odd">
<td align="left"><code>N</code></td>
<td align="left">Total number of cases</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">N</mtext><mo>=</mo><mtext mathvariant="normal">hi</mtext><mo>+</mo><mtext mathvariant="normal">mi</mtext><mo>+</mo><mtext mathvariant="normal">fa</mtext><mo>+</mo><mtext mathvariant="normal">cr</mtext></mrow><annotation encoding="application/x-tex">\text{N} = \text{hi} + \text{mi} + \text{fa} + \text{cr}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<p><strong>Table 1</strong>: Definitions of the frequency counts in a
2x2 confusion table. The notation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">N()</annotation></semantics></math>
means number of cases (or frequency counts).</p>
<div class="section level3">
<h3 id="conditional-accuracy-statistics">Conditional accuracy statistics<a class="anchor" aria-label="anchor" href="#conditional-accuracy-statistics"></a>
</h3>
<p>The first set of accuracy statistics are based on subsets of the
data. These subsets result from focusing on particular cases of interest
and computing conditional probabilities based on them. Given the 2x2
structure of the confusion table, measures can be conditional on either
algorithm decisions (positive predictive vs. negative predictive values)
or criterion values (sensitivity vs. specificity). In other words, these
measures are conditional probabilities that are based on either the rows
or columns of the confusion table:</p>
<table class="table">
<colgroup>
<col width="11%">
<col width="50%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th align="left">Output</th>
<th align="left">Description</th>
<th align="left">Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><code>sens</code></td>
<td align="left">Sensitivity</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">Decision</mtext><mo>=</mo><mn>1</mn><mspace width="0.222em"></mspace><mo stretchy="false" form="postfix">|</mo><mspace width="0.222em"></mspace><mtext mathvariant="normal">Truth</mtext><mo>=</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mtext mathvariant="normal">hi</mtext><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">hi</mtext><mo>+</mo><mtext mathvariant="normal">mi</mtext><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(\text{Decision} = 1 \ \vert\ \text{Truth} = 1) = \text{hi} / (\text{hi} + \text{mi})</annotation></semantics></math></td>
</tr>
<tr class="even">
<td align="left"><code>spec</code></td>
<td align="left">Specificity</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">Decision</mtext><mo>=</mo><mn>0</mn><mspace width="0.222em"></mspace><mo stretchy="false" form="postfix">|</mo><mspace width="0.222em"></mspace><mtext mathvariant="normal">Truth</mtext><mo>=</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mtext mathvariant="normal">cr</mtext><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">cr</mtext><mo>+</mo><mtext mathvariant="normal">fa</mtext><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(\text{Decision} = 0 \ \vert\ \text{Truth} = 0) = \text{cr} / (\text{cr} + \text{fa})</annotation></semantics></math></td>
</tr>
<tr class="odd">
<td align="left"><code>far</code></td>
<td align="left">False alarm rate</td>
<td align="left">
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mtext mathvariant="normal">Specificity</mtext></mrow><annotation encoding="application/x-tex">1 - \text{Specificity}</annotation></semantics></math>
(<code>spec</code>)</td>
</tr>
<tr class="even">
<td align="left"><code>ppv</code></td>
<td align="left">Positive predictive value</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">Truth</mtext><mo>=</mo><mn>1</mn><mspace width="0.222em"></mspace><mo stretchy="false" form="postfix">|</mo><mspace width="0.222em"></mspace><mtext mathvariant="normal">Decision</mtext><mo>=</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mtext mathvariant="normal">hi</mtext><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">hi</mtext><mo>+</mo><mtext mathvariant="normal">fa</mtext><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(\text{Truth} = 1 \ \vert\ \text{Decision} = 1) = \text{hi} / (\text{hi} + \text{fa})</annotation></semantics></math></td>
</tr>
<tr class="odd">
<td align="left"><code>npv</code></td>
<td align="left">Negative predictive value</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">Truth</mtext><mo>=</mo><mn>0</mn><mspace width="0.222em"></mspace><mo stretchy="false" form="postfix">|</mo><mspace width="0.222em"></mspace><mtext mathvariant="normal">Decision</mtext><mo>=</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mtext mathvariant="normal">cr</mtext><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">cr</mtext><mo>+</mo><mtext mathvariant="normal">mi</mtext><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(\text{Truth} = 0 \ \vert\ \text{Decision} = 0) = \text{cr} / (\text{cr} + \text{mi})</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<p><strong>Table 2</strong>: Conditional accuracy statistics based on
either the rows or columns of a 2x2 confusion table.</p>
<p>The <em>sensitivity</em> (aka. <em>hit-rate</em>) is defined as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>e</mi><mi>n</mi><mi>s</mi><mo>=</mo><mi>h</mi><mi>i</mi><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>h</mi><mi>i</mi><mo>+</mo><mi>m</mi><mi>i</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">sens = hi/(hi + mi)</annotation></semantics></math>
and represents the percentage of cases with positive criterion values
that were correctly predicted by the algorithm. Similarly,
<em>specificity</em> (aka. <em>correct rejection rate</em>, or the
complement of the <em>false alarm rate</em>) is defined as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>p</mi><mi>e</mi><mi>c</mi><mo>=</mo><mi>c</mi><mi>r</mi><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>f</mi><mi>a</mi><mo>+</mo><mi>c</mi><mi>r</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">spec = cr/(fa + cr)</annotation></semantics></math>
and represents the percentage of cases with negative criterion values
correctly predicted by the algorithm.</p>
<p>The <em>positive-predictive
value</em> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>p</mi><mi>v</mi></mrow><annotation encoding="application/x-tex">ppv</annotation></semantics></math>
and <em>negative predictive
value</em> <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>p</mi><mi>v</mi></mrow><annotation encoding="application/x-tex">npv</annotation></semantics></math>
are the flip-sides
of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>e</mi><mi>n</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">sens</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>p</mi><mi>e</mi><mi>c</mi></mrow><annotation encoding="application/x-tex">spec</annotation></semantics></math>,
as they are conditional accuracies based on decision outcomes (rather
than on true criterion values).</p>
</div>
<div class="section level3">
<h3 id="aggregate-accuracy-statistics">Aggregate accuracy statistics<a class="anchor" aria-label="anchor" href="#aggregate-accuracy-statistics"></a>
</h3>
<p>Additional accuracy statistics are based on all four cells in the
confusion table:</p>
<table class="table">
<colgroup>
<col width="11%">
<col width="50%">
<col width="37%">
</colgroup>
<thead><tr class="header">
<th align="left">Output</th>
<th align="left">Description</th>
<th align="left">Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><code>acc</code></td>
<td align="left">Accuracy</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">hi</mtext><mo>+</mo><mtext mathvariant="normal">cr</mtext><mo stretchy="true" form="postfix">)</mo></mrow><mi>/</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">hi</mtext><mo>+</mo><mtext mathvariant="normal">mi</mtext><mo>+</mo><mtext mathvariant="normal">fa</mtext><mo>+</mo><mtext mathvariant="normal">cr</mtext><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">(\text{hi} + \text{cr}) / (\text{hi} + \text{mi} + \text{fa} + \text{cr})</annotation></semantics></math></td>
</tr>
<tr class="even">
<td align="left"><code>bacc</code></td>
<td align="left">Balanced accuracy</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">sens</mtext><mo>×</mo><mn>.5</mn><mo>+</mo><mtext mathvariant="normal">spec</mtext><mo>×</mo><mn>.5</mn></mrow><annotation encoding="application/x-tex">\text{sens} \times .5 + \text{spec} \times .5</annotation></semantics></math></td>
</tr>
<tr class="odd">
<td align="left"><code>wacc</code></td>
<td align="left">Weighted accuracy</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">sens</mtext><mo>×</mo><mi>w</mi><mo>+</mo><mtext mathvariant="normal">spec</mtext><mo>×</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>w</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{sens} \times w + \text{spec} \times (1 - w)</annotation></semantics></math></td>
</tr>
<tr class="even">
<td align="left"><code>bpv</code></td>
<td align="left">Balanced predictive value</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="normal">ppv</mtext><mo>×</mo><mn>.5</mn><mo>+</mo><mtext mathvariant="normal">npv</mtext><mo>×</mo><mn>.5</mn></mrow><annotation encoding="application/x-tex">\text{ppv} \times .5 + \text{npv} \times .5</annotation></semantics></math></td>
</tr>
<tr class="odd">
<td align="left"><code>dprime</code></td>
<td align="left">D-prime</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mtext mathvariant="normal">sens</mtext></msub><mo>−</mo><msub><mi>z</mi><mtext mathvariant="normal">far</mtext></msub></mrow><annotation encoding="application/x-tex">z_{\text{sens}} - z_{\text{far}}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<p><strong>Table 3</strong>: Aggregate accuracy statistics based on all
four cells of a 2x2 confusion table.</p>
<p>Overall <em>accuracy</em> (<code>acc</code>) is defined as the
overall percentage of correct decisions ignoring the difference between
hits and correct rejections. The more specific
measures <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>a</mi><mi>c</mi><mi>c</mi></mrow><annotation encoding="application/x-tex">bacc</annotation></semantics></math>
and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi><mi>a</mi><mi>c</mi><mi>c</mi></mrow><annotation encoding="application/x-tex">wacc</annotation></semantics></math>
are averages of sensitivity and specificity,
while <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>p</mi><mi>v</mi></mrow><annotation encoding="application/x-tex">bpv</annotation></semantics></math>
is an average of predictive values. The
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>p</mi><mi>r</mi><mi>i</mi><mi>m</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">dprime</annotation></semantics></math>
measure is the difference in standardized
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>z</mi><annotation encoding="application/x-tex">z</annotation></semantics></math>-score)
transformed <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>e</mi><mi>n</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">sens</annotation></semantics></math>
and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mi>a</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">far</annotation></semantics></math><span class="citation">(see Luan et al., 2011 for the relation between
FFTs and signal detection theory, SDT)</span>.</p>
</div>
<div class="section level3">
<h3 id="speed-and-frugality-statistics">Speed and frugality statistics<a class="anchor" aria-label="anchor" href="#speed-and-frugality-statistics"></a>
</h3>
<p>The next two statistics measure the speed and frugality of a
fast-and-frugal tree (FFT). Unlike the accuracy statistics above, they
are <em>not</em> based on the confusion table. Rather, they depend on
how much information FFTs use to make their predictions or
decisions.</p>
<table class="table">
<colgroup>
<col width="9%">
<col width="58%">
<col width="31%">
</colgroup>
<thead><tr class="header">
<th align="left">Output</th>
<th align="left">Description</th>
<th align="left">Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><code>mcu</code></td>
<td align="left">Mean cues used: Average number of cue values used in
making classifications, averaged across all cases</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"><code>pci</code></td>
<td align="left">Percentage of cues ignored: Percentage of cues ignored
when classifying cases</td>
<td align="left"><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mrow><mo stretchy="true" form="prefix">(</mo><mtext mathvariant="normal">cues in data</mtext><mo stretchy="true" form="postfix">)</mo></mrow><mo>−</mo><mtext mathvariant="normal">mcu</mtext></mrow><annotation encoding="application/x-tex">N(\text{cues in data}) - \text{mcu}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<p><strong>Table 4</strong>: Measures to quantify the speed and
frugality of FFTs.</p>
<p>To see exactly where these statistics come from, let’s look at the
results for <code>heart.fft</code> (Tree #1):</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">heart.fft</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; <span style="color: #005FAF;">FFTrees </span></span></span>
<span><span class="co">#&gt; - Trees: 7 fast-and-frugal trees predicting <span style="text-decoration: underline;">diagnosis</span></span></span>
<span><span class="co">#&gt; - Cost of outcomes:  hi = 0,  fa = 1,  mi = 1,  cr = 0</span></span>
<span><span class="co">#&gt; - Cost of cues: </span></span>
<span><span class="co">#&gt;      age      sex       cp trestbps     chol      fbs  restecg  thalach </span></span>
<span><span class="co">#&gt;        1        1        1        1        1        1        1        1 </span></span>
<span><span class="co">#&gt;    exang  oldpeak    slope       ca     thal </span></span>
<span><span class="co">#&gt;        1        1        1        1        1 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #005FAF;">FFT #1: Definition</span></span></span>
<span><span class="co">#&gt; [1] If thal = {rd,fd}, decide True.</span></span>
<span><span class="co">#&gt; [2] If cp != {a}, decide False.</span></span>
<span><span class="co">#&gt; [3] If ca &gt; 0, decide True, otherwise, decide False.</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #005FAF;">FFT #1: </span><span style="color: #005FAF; text-decoration: underline;">Training</span><span style="color: #005FAF;"> Accuracy</span></span></span>
<span><span class="co"><span style="color: #005FAF;">#&gt; </span>Training data: N = 303, Pos (+) = 139 (46%) </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; |          | True + | True - | Totals:</span></span>
<span><span class="co">#&gt; |----------|--------|--------|</span></span>
<span><span class="co">#&gt; | Decide + | <span style="color: #767676;">hi</span> <span style="color: #00AF00;">118</span> | <span style="color: #767676;">fa</span>  <span style="color: #D70000;">37</span> |     155</span></span>
<span><span class="co">#&gt; | Decide - | <span style="color: #767676;">mi</span>  <span style="color: #D70000;">21</span> | <span style="color: #767676;">cr</span> <span style="color: #00AF00;">127</span> |     148</span></span>
<span><span class="co">#&gt; |----------|--------|--------|</span></span>
<span><span class="co">#&gt;   Totals:       139      164   N = <span style="text-decoration: underline;">303</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; acc  = 80.9%   ppv  = 76.1%   npv  = 85.8%</span></span>
<span><span class="co">#&gt; bacc = 81.2%   sens = 84.9%   spec = 77.4%</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; <span style="color: #005FAF;">FFT #1: </span><span style="color: #005FAF; text-decoration: underline;">Training</span><span style="color: #005FAF;"> Speed, Frugality, and Cost</span></span></span>
<span><span class="co"><span style="color: #005FAF;">#&gt; </span>mcu = 1.73,  pci = 0.87</span></span>
<span><span class="co">#&gt; cost_dec = 0.191,  cost_cue = 1.733,  cost = 1.924</span></span></code></pre>
<p>According to this output, Tree #1 has <code>mcu = 1.73</code> and
<code>pci = 0.87</code>. We can easily calculate these measures directly
from the <code>x$levelout</code> output of an <code>FFTrees</code>
object. This object contains the tree level (i.e., node) at which each
case was classified:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># A vector of levels/nodes at which each case was classified:</span></span>
<span><span class="va">heart.fft</span><span class="op">$</span><span class="va">trees</span><span class="op">$</span><span class="va">decisions</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">tree_1</span><span class="op">$</span><span class="va">levelout</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt;   [1] 1 3 1 2 2 2 3 3 1 1 1 2 1 1 1 2 1 3 2 2 2 2 2 1 1 2 2 2 3 1 2 1 2 1 2 3 1</span></span>
<span><span class="co">#&gt;  [38] 1 1 2 1 1 2 2 3 1 2 1 2 2 2 1 3 2 1 1 1 1 2 2 1 2 1 2 1 1 2 1 1 2 2 1 1 1</span></span>
<span><span class="co">#&gt;  [75] 3 2 1 2 2 1 3 3 2 1 2 2 2 2 3 2 3 1 1 2 2 1 1 1 2 3 3 2 3 2 1 1 1 1 1 1 1</span></span>
<span><span class="co">#&gt; [112] 3 1 1 1 1 2 3 1 1 1 1 2 1 2 2 1 1 2 3 1 1 2 3 2 2 1 1 1 2 2 1 2 1 1 2 1 2</span></span>
<span><span class="co">#&gt; [149] 2 2 1 3 1 1 3 3 1 1 1 1 1 3 2 3 2 1 2 2 1 2 1 1 3 3 1 1 1 1 2 2 1 1 2 1 3</span></span>
<span><span class="co">#&gt; [186] 2 1 1 1 1 2 1 1 3 2 3 2 3 2 2 3 3 1 1 1 1 1 1 2 3 2 1 2 1 3 1 2 3 3 3 2 2</span></span>
<span><span class="co">#&gt; [223] 2 1 3 2 3 2 3 3 2 3 2 2 2 3 1 1 2 2 2 2 3 2 2 3 1 3 1 2 1 1 1 2 3 2 3 2 2</span></span>
<span><span class="co">#&gt; [260] 1 2 2 2 2 3 1 3 1 1 2 1 1 1 3 2 1 2 2 2 3 1 2 1 2 1 1 1 1 1 2 1 2 1 1 3 2</span></span>
<span><span class="co">#&gt; [297] 1 1 1 1 1 2 2</span></span></code></pre>
<p>Now, to calculate <code>mcu</code> (the <em>mean number of cues
used</em>), we simply take the mean of this vector:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Calculate the mean number or cues used (mcu): </span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">heart.fft</span><span class="op">$</span><span class="va">trees</span><span class="op">$</span><span class="va">decisions</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">tree_1</span><span class="op">$</span><span class="va">levelout</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; [1] 1.732673</span></span></code></pre>
<p>Now that we know where <code>mcu</code> comes from, computing
<code>pci</code> (i.e., the <em>percentage of cues ignored</em>) is just
as simple — it’s just the total number of cues in the dataset
minus <code>mcu</code>, divided by the total number of cues in the
data:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Calculate pci (percentage of cues ignored) as </span></span>
<span><span class="co"># (n.cues - mcu) / n.cues):</span></span>
<span><span class="va">n.cues</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">heartdisease</span><span class="op">)</span> </span>
<span><span class="op">(</span><span class="va">n.cues</span> <span class="op">-</span> <span class="va">heart.fft</span><span class="op">$</span><span class="va">trees</span><span class="op">$</span><span class="va">stats</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">mcu</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span> <span class="op">/</span> <span class="va">n.cues</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; [1] 0.8762376</span></span></code></pre>
<!-- Reference for further measures: -->
</div>
<div class="section level3">
<h3 id="additional-measures">Additional measures<a class="anchor" aria-label="anchor" href="#additional-measures"></a>
</h3>
<p>There is a wide range of additional measures that can be used to
quantify classification performance. Most of these can easily be
computed from the numerical information provided in an
<code>FFTrees</code> object. For alternative measures based on the
frequency counts of a 2x2 matrix, see <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2020.567817/full#h5" class="external-link">Table
3</a> of <span class="citation">Neth et al. (2021)</span>.</p>
<!-- - Neth, H., Gradwohl, N., Streeb, D., Keim, D.A., & Gaissmaier, W. (2021).  -->
<!-- Perspectives on the 2×2 matrix: Solving semantically distinct problems based on a shared structure of binary contingencies. _Frontiers in Psychology_, _11_, 567817. doi: [10.3389/fpsyg.2020.567817](https://doi.org/10.3389/fpsyg.2020.567817) -->
</div>
</div>
<div class="section level2">
<h2 id="vignettes">Vignettes<a class="anchor" aria-label="anchor" href="#vignettes"></a>
</h2>
<!-- Table of all vignettes: -->
<p>Here is a complete list of the vignettes available in the
<strong>FFTrees</strong> package:</p>
<table class="table">
<colgroup>
<col width="3%">
<col width="36%">
<col width="59%">
</colgroup>
<thead><tr class="header">
<th align="right"></th>
<th align="left">Vignette</th>
<th align="left">Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right"></td>
<td align="left"><a href="guide.html">Main guide: FFTrees
overview</a></td>
<td align="left">An overview of the <strong>FFTrees</strong>
package</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left"><a href="FFTrees_heart.html">Tutorial: FFTs for heart
disease</a></td>
<td align="left">An example of using <code><a href="../reference/FFTrees.html">FFTrees()</a></code> to model
heart disease diagnosis</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="left"><a href="FFTrees_accuracy_statistics.html">Accuracy
statistics</a></td>
<td align="left">Definitions of accuracy statistics used throughout the
package</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="left"><a href="FFTrees_function.html">Creating FFTs with
FFTrees()</a></td>
<td align="left">Details on the main <code><a href="../reference/FFTrees.html">FFTrees()</a></code>
function</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="left"><a href="FFTrees_mytree.html">Specifying FFTs
directly</a></td>
<td align="left">How to directly create FFTs without using the built-in
algorithms</td>
</tr>
<tr class="even">
<td align="right">5</td>
<td align="left"><a href="FFTrees_plot.html">Visualizing FFTs</a></td>
<td align="left">Plotting <code>FFTrees</code> objects, from full trees
to icon arrays</td>
</tr>
<tr class="odd">
<td align="right">6</td>
<td align="left"><a href="FFTrees_examples.html">Examples of
FFTs</a></td>
<td align="left">Examples of FFTs from different datasets contained in
the package</td>
</tr>
</tbody>
</table>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<!-- eof. -->
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0" line-spacing="2">
<div id="ref-luan2011signal" class="csl-entry">
Luan, S., Schooler, L. J., &amp; Gigerenzer, G. (2011). A
signal-detection analysis of fast-and-frugal trees. <em>Psychological
Review</em>, <em>118</em>(2), 316–338. <a href="https://doi.org/10.1037/a0022684" class="external-link">https://doi.org/10.1037/a0022684</a>
</div>
<div id="ref-neth2021matrix" class="csl-entry">
Neth, H., Gradwohl, N., Streeb, D., Keim, D. A., &amp; Gaissmaier, W.
(2021). <span class="nocase">Perspectives on the 2x2 Matrix: Solving
semantically distinct problems based on a shared structure of binary
contingencies</span>. <em>Frontiers in Psychology</em>, <em>11</em>,
567817. <a href="https://doi.org/10.3389/fpsyg.2020.567817" class="external-link">https://doi.org/10.3389/fpsyg.2020.567817</a>
</div>
<div id="ref-phillips2017FFTrees" class="csl-entry">
Phillips, N. D., Neth, H., Woike, J. K., &amp; Gaissmaier, W. (2017).
<span class="nocase">FFTrees: A toolbox to create, visualize, and
evaluate fast-and-frugal decision trees</span>. <em>Judgment and
Decision Making</em>, <em>12</em>(4), 344–368. <a href="https://doi.org/10.1017/S1930297500006239" class="external-link">https://doi.org/10.1017/S1930297500006239</a>
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Nathaniel Phillips, Hansjoerg Neth, Jan Woike, Wolfgang Gaissmaier.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
